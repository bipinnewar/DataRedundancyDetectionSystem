{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f293051e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bipin Shrestha\\AppData\\Local\\Temp\\ipykernel_18192\\2895056622.py:79: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df = pd.read_csv(file, infer_datetime_format=True, encoding='ISO-8859-1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............Dataset..........\n",
      "ID: 1, std_att: bipin22male9800000000\n",
      "ID: 2, std_att: bishal20female9811111111\n",
      "ID: 3, std_att: ajay22male9866844509\n",
      "ID: 4, std_att: bipin22male9800000000\n",
      "ID: 5, std_att: rita19female9812345678\n",
      "ID: 6, std_att: bipin22male9800000088\n",
      "ID: 7, std_att: ram80male9811111111\n",
      "ID: 8, std_att: sit22female9800000000\n",
      "ID: 9, std_att: oracle22female9196856201\n",
      "ID: 10, std_att: oracle90female9196856201\n",
      "...........Edit Distance without sorting: ...........\n",
      "...........Edit Distance in Sorted order.............\n",
      "Edit distance between (1)bipin22male9800000000 and (4)bipin22male9800000000 : 0\n",
      "Edit distance between (1)bipin22male9800000000 and (6)bipin22male9800000088 : 2\n",
      "Edit distance between (4)bipin22male9800000000 and (6)bipin22male9800000088 : 2\n",
      "Edit distance between (9)oracle22female9196856201 and (10)oracle90female9196856201 : 2\n",
      "..........Dataset within the edit distance with unique id.............\n",
      "[(np.int64(1), 'bipin22male9800000000'), (np.int64(4), 'bipin22male9800000000'), (np.int64(6), 'bipin22male9800000088'), (np.int64(9), 'oracle22female9196856201'), (np.int64(10), 'oracle90female9196856201')]\n",
      "Length of unique attribute(edit distance):  5\n",
      "\n",
      " \n",
      " \n",
      " Processing time: 14.456584215164185 seconds\n"
     ]
    }
   ],
   "source": [
    "import tkinter\n",
    "from tkinter import *\n",
    "from tkinter import filedialog \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "def edit_distance(s1, s2):\n",
    "    m = len(s1)\n",
    "    n = len(s2)\n",
    "\n",
    "    # initialize the matrix\n",
    "    d = [[0] * (n + 1) for i in range(m + 1)]\n",
    "\n",
    "    # fill the first row and first column\n",
    "    for i in range(1, m + 1):\n",
    "        d[i][0] = i\n",
    "    for j in range(1, n + 1):\n",
    "        d[0][j] = j\n",
    "\n",
    "    # fill the rest of the matrix\n",
    "    for j in range(1, n + 1):\n",
    "        for i in range(1, m + 1):\n",
    "            if s1[i - 1] == s2[j - 1]:\n",
    "                d[i][j] = d[i - 1][j - 1]\n",
    "            else:\n",
    "                d[i][j] = min(d[i - 1][j], d[i][j - 1], d[i - 1][j - 1]) + 1\n",
    "\n",
    "    # return the final value in the matrix\n",
    "    return d[m][n]\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "def count_duplicates(records):\n",
    "    count_dict = {}\n",
    "\n",
    "    for row in records:\n",
    "        record = tuple(row[1:]) # discard column 1\n",
    "\n",
    "        if record in count_dict:\n",
    "            count_dict[record] ['count']+= 1\n",
    "            count_dict[record]['ids'].append(row[0]) # add ID to list of IDs\n",
    "\n",
    "        else:\n",
    "            count_dict[record] = {'count': 1, 'ids': [row[0]]}\n",
    "\n",
    "    duplicates = []\n",
    "    total=0         \n",
    "    for record, count_dict in count_dict.items():\n",
    "         if count_dict['count'] > 1:\n",
    "            duplicates.append(f\"IDs: {', '.join(str(id) for id in count_dict['ids'])},{record}: duplicate count: {count_dict['count']} \")\n",
    "            total=total+count_dict['count']\n",
    "            \n",
    "    lbl_total=Label(window, text=\"Number of Duplicates: {}\".format(total))\n",
    "    lbl_total.pack()            \n",
    "    \n",
    "    return duplicates\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "def upload_file():\n",
    "    \n",
    "    file=filedialog.askopenfilename(title=\"Select file\" , filetypes=[(\"CSV files\", '.csv')])\n",
    "    if(file):\n",
    "        lbl_my_file=Label(window, text=\"File read!\", font=(\"arial\", 12, \"bold\") )\n",
    "        lbl_my_file.pack()\n",
    "        \n",
    "        comparison=0\n",
    "        threshold=5\n",
    "        chunk_size=50\n",
    "        \n",
    "        probable=[]\n",
    "        probable_dup=[]\n",
    "        \n",
    "        df = pd.read_csv(file, infer_datetime_format=True, encoding='ISO-8859-1')\n",
    "        \n",
    "        file_name.set(file)\n",
    "        \n",
    "        # Clean up the data\n",
    "        # df.dropna(subset=['name', 'age', 'age_unit', 'province_id', 'district_id', 'municipality_id', 'tole', 'ward', 'caste', 'sex'], inplace=True)\n",
    "        df.dropna(subset=['name', 'age', 'gender', 'number'], inplace=True)\n",
    "        \n",
    "        df[\"name\"] = df[\"name\"].str.replace(\" \", \"\")\n",
    "        # std = df[['id', 'name', 'age', 'age_unit', 'province_id', 'district_id', 'municipality_id',\n",
    "        #           'tole', 'ward', 'caste', 'sex']].values\n",
    "        std = df[['id', 'name', 'age', 'gender', 'number']].values\n",
    "        \n",
    "        # df['std_att'] = df.apply(lambda row: str(row['name']) + str(row['age']) + str(row['age_unit'])\n",
    "        #                          + str(row['province_id']) + str(row['district_id']) + str(row['municipality_id']) \n",
    "        #                          + str(row['tole']) + str(row['ward']) + str(row['caste']) + str(row['sex']), axis=1)\n",
    "        df['std_att'] = df.apply(lambda row: str(row['name']) + str(row['age']) + str(row['gender'])\n",
    "                                 + str(row['number']), axis=1)\n",
    "        # std_att = df['name'].astype(str) + df['age'].astype(str) + df['age_unit'].astype(str) \n",
    "        std_att = df['name'].astype(str) + df['age'].astype(str) + df['gender'].astype(str) + df['number'].astype(str) \n",
    "    \n",
    "        print(\"............Dataset..........\")\n",
    "        for index, row in df.iterrows():\n",
    "            a=f\"ID: {row['id']}, std_att: {row['std_att']}\"\n",
    "            print(a)\n",
    "    \n",
    "    \n",
    "        mylist = Text(window, height=15, width=150)\n",
    "        mylist.pack(side=TOP, padx=10, pady=10, expand=True)\n",
    "\n",
    "              \n",
    "        mylist1 = Text(window, height=15, width=150)\n",
    "        mylist1.pack(side=BOTTOM, padx=10, pady=10, expand=True)\n",
    "        \n",
    "        unique_ids = [] # list to store unique IDs\n",
    "        unique_std_att = [] # list to store corresponding unique std_att values\n",
    "       \n",
    "       \n",
    "        \n",
    "        print(\"...........Edit Distance without sorting: ...........\")\n",
    "        for i in range(0, len(df), chunk_size):\n",
    "            chunk = df.iloc[i:i+chunk_size]\n",
    "            std_chunk=std_att.iloc[i:i+chunk_size]\n",
    "            m = len(chunk)\n",
    "            for j in range(m):\n",
    "                for k in range(j + 1, m):\n",
    "                    id_j = str(chunk.iloc[j]['id'])\n",
    "                    id_k = str(chunk.iloc[k]['id'])\n",
    "                    dist = edit_distance(std_chunk.iloc[j], std_chunk.iloc[k])\n",
    "                    comparison += 1 # m * (m - 1) / 2\n",
    "                    if dist == 2 or dist ==1 :\n",
    "                        edit = (dist, f\"Edit distance between ({id_j}){chunk.iloc[j]['std_att']} and ({id_k}){chunk.iloc[k]['std_att']} : {dist}\")\n",
    "                        probable_dup.append(edit)\n",
    "                        \n",
    "                      \n",
    "                        \n",
    "                    if dist <= threshold:                       \n",
    "                        pair = (dist, f\"Edit distance between ({id_j}){chunk.iloc[j]['std_att']} and ({id_k}){chunk.iloc[k]['std_att']} : {dist}\")\n",
    "                        probable.append(pair)    \n",
    "                        \n",
    "                        if id_j not in unique_ids:\n",
    "                            unique_ids.append(id_j)\n",
    "                            unique_std_att.append((chunk.iloc[j]['id'], chunk.iloc[j]['std_att']))\n",
    "                            \n",
    "                        if id_k not in unique_ids:\n",
    "                            unique_ids.append(id_k)\n",
    "                            unique_std_att.append((chunk.iloc[k]['id'], chunk.iloc[k]['std_att']))\n",
    "                            \n",
    "        print(\"...........Edit Distance in Sorted order.............\")                    \n",
    "        probable = sorted(probable, key=lambda x: x[0]) # sort by distance\n",
    "        for pair in probable:\n",
    "            print(pair[1])   \n",
    "        \n",
    "        probable_dup = sorted(probable_dup, key=lambda x: x[0]) # sort by distance\n",
    "        mylist1.insert(END,f\"Probable Dupliates:\\n\")\n",
    "        z = 1\n",
    "        for edit in probable_dup:\n",
    "            mylist1.insert(END,f\"{z}: {edit[1]}\\n\")\n",
    "            z=z+1\n",
    "        mylist1.config(state='disabled')\n",
    "\n",
    "              \n",
    "        print(\"..........Dataset within the edit distance with unique id.............\")\n",
    "        print(unique_std_att)\n",
    "        print(\"Length of unique attribute(edit distance): \", len(unique_std_att))\n",
    "\n",
    "        duplicates = count_duplicates(unique_std_att)\n",
    "        mylist.insert(END,f\"Exact Dupliates:\\n\")\n",
    "        for i in range(len(duplicates)):\n",
    "            mylist.insert(END,f\"{i+1}: {duplicates[i]}\\n\" )\n",
    "        mylist.config(state='disabled')\n",
    "        \n",
    "        lbl_data=Label(window, text=\"Number of data in dataset: {}\".format(len(std_att)))\n",
    "        lbl_data.pack()\n",
    "             \n",
    "        lbl_comparison=Label(window, text=\"Number of Comparison: {}\".format(comparison))\n",
    "        lbl_comparison.pack()            \n",
    "                \n",
    "\n",
    "window=Tk()\n",
    "window.geometry(\"1000x800\")\n",
    "window.title(\"Data Redundancy Detection System\")\n",
    "title_lbl=Label(window, text=\"Upload .csv file\", font=(\"arial\", 30, \"italic bold\"),bd=7)\n",
    "title_lbl.pack()\n",
    "button=Button(window, text=\"Upload File\", relief=RAISED,font=(\"arial\", 15, \"bold\"), width=15, bg=\"light blue\" ,command=upload_file)\n",
    "button.pack()\n",
    "\n",
    "file_name=StringVar()\n",
    "file_data=StringVar()\n",
    "my_file=StringVar()\n",
    "\n",
    "lbl_name=Label(window, textvariable=file_name)\n",
    "lbl_name.pack()\n",
    "\n",
    "\n",
    "window.mainloop()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "processing_time = end_time - start_time\n",
    "print(f\"\\n \\n \\n Processing time: {processing_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0966417f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b593221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c190ed99",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45304509",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
